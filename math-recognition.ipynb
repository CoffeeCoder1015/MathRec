{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-12T05:56:38.018842Z",
     "iopub.status.busy": "2025-11-12T05:56:38.018247Z",
     "iopub.status.idle": "2025-11-12T05:56:38.800968Z",
     "shell.execute_reply": "2025-11-12T05:56:38.800160Z",
     "shell.execute_reply.started": "2025-11-12T05:56:38.018819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '\\\\rightarrow' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' '\\\\pi' '\\\\alpha' '\\\\beta' '\\\\sum' '\\\\sigma' 'a' 'b' 'c'\n",
      " 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 'u' 'v'\n",
      " 'w' 'x' 'y' 'z' '\\\\Sigma' '\\\\gamma' '\\\\Gamma' '\\\\delta' '\\\\Delta'\n",
      " '\\\\zeta' '\\\\eta' '\\\\theta' '\\\\Theta' '\\\\epsilon' '\\\\varepsilon' '\\\\iota'\n",
      " '\\\\kappa' '\\\\varkappa' '\\\\lambda' '\\\\Lambda' '\\\\mu' '\\\\nu' '\\\\xi' '\\\\Xi'\n",
      " '\\\\Pi' '\\\\rho' '\\\\varrho' '\\\\tau' '\\\\phi' '\\\\Phi' '\\\\varphi' '\\\\chi'\n",
      " '\\\\psi' '\\\\Psi' '\\\\omega' '\\\\Omega' '\\\\partial' '\\\\int' '\\\\cdot' '\\\\leq'\n",
      " '\\\\geq' '<' '>' '\\\\subset' '\\\\supset' '\\\\subseteq' '\\\\supseteq' '\\\\cong'\n",
      " '\\\\propto' '-' '+' '\\\\mathbb{R}' '\\\\$' '\\\\{' '\\\\copyright' '\\\\dots' '\\\\}'\n",
      " '\\\\S' '\\\\dag' '\\\\pounds' '\\\\&' '\\\\#' '\\\\%' '\\\\checkmark' '\\\\circledR'\n",
      " '\\\\mathsection' '\\\\amalg' '\\\\cup' '\\\\oplus' '\\\\times' '\\\\ast'\n",
      " '\\\\triangleleft' '\\\\otimes' '\\\\triangleright' '\\\\diamond' '\\\\pm' '\\\\div'\n",
      " '\\\\bullet' '\\\\setminus' '\\\\uplus' '\\\\cap' '\\\\mp' '\\\\sqcap' '\\\\vee'\n",
      " '\\\\odot' '\\\\sqcup' '\\\\wedge' '\\\\circ' '\\\\ominus' '\\\\star' '\\\\wr'\n",
      " '\\\\barwedge' '\\\\circledcirc' '\\\\boxdot' '\\\\ltimes' '\\\\boxplus'\n",
      " '\\\\boxtimes' '\\\\rtimes' '\\\\circledast' '\\\\lhd' '\\\\prod' '\\\\coprod'\n",
      " '\\\\oint' '\\\\parr' '\\\\with' '\\\\fint' '\\\\varoiint' '\\\\oiint' '\\\\approx'\n",
      " '\\\\equiv' '\\\\not\\\\equiv' '\\\\perp' '\\\\asymp' '\\\\frown' '\\\\prec' '\\\\succ'\n",
      " '\\\\bowtie' '\\\\preceq' '\\\\succeq' '\\\\mid' '\\\\vdash' '\\\\dashv' '\\\\models'\n",
      " '\\\\sim' '\\\\doteq' '\\\\parallel' '\\\\simeq' '\\\\backsim' '\\\\multimap'\n",
      " '\\\\pitchfork' '\\\\therefore' '\\\\because' '\\\\between' '\\\\preccurlyeq'\n",
      " '\\\\varpropto' '\\\\Vdash' '\\\\vDash' '\\\\nmid' '\\\\nvDash' '\\\\sqsubseteq'\n",
      " '\\\\nsubseteq' '\\\\subsetneq' '\\\\varsubsetneq' '\\\\neq' '\\\\geqslant'\n",
      " '\\\\gtrless' '\\\\lesssim' '\\\\gtrsim' '\\\\leqslant' '\\\\trianglelefteq'\n",
      " '\\\\blacktriangleright' '\\\\triangleq' '\\\\Downarrow' '\\\\downarrow'\n",
      " '\\\\Rightarrow' '\\\\hookrightarrow' '\\\\Longleftrightarrow' '\\\\searrow'\n",
      " '\\\\longmapsto' '\\\\leftarrow' '\\\\Longrightarrow' '\\\\uparrow' '\\\\Leftarrow'\n",
      " '\\\\longrightarrow' '\\\\Leftrightarrow' '\\\\mapsto' '\\\\leftrightarrow'\n",
      " '\\\\nearrow' '\\\\rightleftharpoons' '\\\\rightharpoonup' '\\\\leadsto'\n",
      " '\\\\circlearrowleft' '\\\\rightleftarrows' '\\\\circlearrowright'\n",
      " '\\\\rightrightarrows' '\\\\rightsquigarrow' '\\\\curvearrowright'\n",
      " '\\\\twoheadrightarrow' '\\\\nRightarrow' '\\\\nrightarrow' '\\\\upharpoonright'\n",
      " '\\\\mapsfrom' '\\\\shortrightarrow' '\\\\lightning' '\\\\vartheta' '\\\\varpi'\n",
      " '\\\\bot' '\\\\forall' '\\\\ni' '\\\\top' '\\\\ell' '\\\\hbar' '\\\\in' '\\\\notin'\n",
      " '\\\\wp' '\\\\exists' '\\\\Im' '\\\\Re' '\\\\nexists' '\\\\langle' '\\\\rangle'\n",
      " '\\\\lceil' '\\\\rceil' '\\\\lfloor' '\\\\rfloor' '[' ']' '|' '\\\\|' '/'\n",
      " '\\\\llbracket' '\\\\rrbracket' '\\\\vdots' '\\\\ddots' '\\\\dotsc' '\\\\aleph'\n",
      " '\\\\infty' '\\\\prime' '\\\\angle' '\\\\diamondsuit' '\\\\sharp' '\\\\backslash'\n",
      " '\\\\emptyset' '\\\\nabla' '\\\\flat' '\\\\clubsuit' '\\\\heartsuit' '\\\\neg'\n",
      " '\\\\triangle' '\\\\sqrt{}' '\\\\sphericalangle' '\\\\square' '\\\\triangledown'\n",
      " '\\\\blacksquare' '\\\\lozenge' '\\\\varnothing' '\\\\vartriangle' '\\\\iddots'\n",
      " '\\\\mathcal{A}' '\\\\mathcal{B}' '\\\\mathcal{C}' '\\\\mathcal{D}'\n",
      " '\\\\mathcal{E}' '\\\\mathcal{F}' '\\\\mathcal{G}' '\\\\mathcal{H}'\n",
      " '\\\\mathcal{L}' '\\\\mathcal{M}' '\\\\mathcal{N}' '\\\\mathcal{O}'\n",
      " '\\\\mathcal{P}' '\\\\mathcal{R}' '\\\\mathcal{S}' '\\\\mathcal{T}'\n",
      " '\\\\mathcal{U}' '\\\\mathcal{X}' '\\\\mathcal{Z}' '\\\\mathfrak{A}'\n",
      " '\\\\mathfrak{M}' '\\\\mathfrak{S}' '\\\\mathfrak{X}' '\\\\mathbb{1}'\n",
      " '\\\\mathds{1}' '\\\\mathds{C}' '\\\\mathds{E}' '\\\\mathds{N}' '\\\\mathds{P}'\n",
      " '\\\\mathds{Q}' '\\\\mathds{R}' '\\\\mathds{Z}' '\\\\mathscr{A}' '\\\\mathscr{C}'\n",
      " '\\\\mathscr{D}' '\\\\mathscr{E}' '\\\\mathscr{F}' '\\\\mathscr{H}'\n",
      " '\\\\mathscr{L}' '\\\\mathscr{P}' '\\\\mathscr{S}' '\\\\celsius' '\\\\degree'\n",
      " '\\\\ohm' '\\\\venus' '\\\\mars' '\\\\astrosun' '\\\\fullmoon' '\\\\leftmoon'\n",
      " '\\\\female' '\\\\male' '\\\\checked' '\\\\diameter' '\\\\sun' '\\\\Bowtie'\n",
      " '\\\\mathbb{Q}' '\\\\mathbb{N}' '\\\\mathbb{Z}' '\\\\mathbb{H}' '\\\\ss' '\\\\aa'\n",
      " '\\\\L' '\\\\AA' '\\\\O' '\\\\o' '\\\\ae' '\\\\AE' '\\\\guillemotleft']\n",
      "370 many symbols\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "root = \"/kaggle/input/hasyv2-dataset-friend-of-mnist/HASYv2\"\n",
    "\n",
    "print(pd.read_csv(root+\"/hasy-data-labels.csv\")[\"latex\"].unique())\n",
    "\n",
    "start = root+\"/classification-task/fold-1\"\n",
    "\n",
    "train_csv = pd.read_csv(start+\"/train.csv\")\n",
    "test_csv = pd.read_csv(start+\"/test.csv\")\n",
    "\n",
    "classes = train_csv[\"latex\"].unique()\n",
    "hashed_class = {v:i for i,v in enumerate(classes)}\n",
    "span = len(classes)+1\n",
    "print(span,\"many symbols\")\n",
    "\n",
    "def get_target_ids(symbols):\n",
    "    return np.array([hashed_class[s] for s in symbols])\n",
    "    \n",
    "def get_targets(symbols):\n",
    "    base = np.zeros(shape=(len(symbols),span))\n",
    "    for i,s in enumerate(symbols):\n",
    "        idx = hashed_class[s]\n",
    "        base[i][idx] = 1\n",
    "    return base\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T05:56:41.755771Z",
     "iopub.status.busy": "2025-11-12T05:56:41.755087Z",
     "iopub.status.idle": "2025-11-12T05:56:49.429033Z",
     "shell.execute_reply": "2025-11-12T05:56:49.428402Z",
     "shell.execute_reply.started": "2025-11-12T05:56:41.755746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to [C, H, W], scales 0-255 to 0-1\n",
    "    # Optionally normalize to mean=0.5, std=0.5 (common for grayscale)\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class HASYDataset(Dataset):\n",
    "    def __init__(self, train_csv_df):\n",
    "        self.csv = train_csv_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        obj = self.csv.iloc[idx]\n",
    "        path = start+\"/\"+obj[\"path\"]\n",
    "        label = obj[\"latex\"]\n",
    "        image = transform(Image.open(path).convert(\"L\"))\n",
    "        return image,label\n",
    "\n",
    "TrainData = HASYDataset(train_csv)\n",
    "\n",
    "dataloader = DataLoader(TrainData, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T05:56:52.176943Z",
     "iopub.status.busy": "2025-11-12T05:56:52.176211Z",
     "iopub.status.idle": "2025-11-12T05:56:52.181562Z",
     "shell.execute_reply": "2025-11-12T05:56:52.180960Z",
     "shell.execute_reply.started": "2025-11-12T05:56:52.176897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- NEW: SAVE AND LOAD FUNCTIONS ---\n",
    "def save_checkpoint(model, path):\n",
    "    \"\"\"Saves only the model's state_dict.\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"\\n--- Weights successfully saved to {path} ---\")\n",
    "\n",
    "def load_checkpoint(model, path, device):\n",
    "    \"\"\"Loads weights from path into the model.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        # Load the weights, mapping them to the current device (CPU or GPU)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        print(f\"--- Weights successfully loaded from {path} ---\")\n",
    "    else:\n",
    "        print(f\"--- Checkpoint file not found at {path}. Starting from scratch. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:09:03.423586Z",
     "iopub.status.busy": "2025-11-12T06:09:03.423269Z",
     "iopub.status.idle": "2025-11-12T06:24:42.925257Z",
     "shell.execute_reply": "2025-11-12T06:24:42.924305Z",
     "shell.execute_reply.started": "2025-11-12T06:09:03.423559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Starting Training ---\n",
      "Model: SimpleNet (Classes: 370, Initial LR: 0.001)\n",
      "Epoch [1/10] | Batch [4727/4727] | Loss: 1.7229 | Acc: 58.30% | LR: 0.000976\n",
      "--- EPOCH 1 SUMMARY ---\n",
      "Average Loss: 1.7229\n",
      "Accuracy: 58.30%\n",
      "\n",
      "Epoch [2/10] | Batch [4727/4727] | Loss: 0.8137 | Acc: 76.78% | LR: 0.000905\n",
      "--- EPOCH 2 SUMMARY ---\n",
      "Average Loss: 0.8137\n",
      "Accuracy: 76.78%\n",
      "\n",
      "Epoch [3/10] | Batch [4727/4727] | Loss: 0.6777 | Acc: 79.70% | LR: 0.000794\n",
      "--- EPOCH 3 SUMMARY ---\n",
      "Average Loss: 0.6777\n",
      "Accuracy: 79.70%\n",
      "\n",
      "Epoch [4/10] | Batch [4727/4727] | Loss: 0.5877 | Acc: 81.61% | LR: 0.000655\n",
      "--- EPOCH 4 SUMMARY ---\n",
      "Average Loss: 0.5877\n",
      "Accuracy: 81.61%\n",
      "\n",
      "Epoch [5/10] | Batch [4727/4727] | Loss: 0.5180 | Acc: 83.31% | LR: 0.000500\n",
      "--- EPOCH 5 SUMMARY ---\n",
      "Average Loss: 0.5180\n",
      "Accuracy: 83.31%\n",
      "\n",
      "Epoch [6/10] | Batch [4727/4727] | Loss: 0.4562 | Acc: 84.61% | LR: 0.000345\n",
      "--- EPOCH 6 SUMMARY ---\n",
      "Average Loss: 0.4562\n",
      "Accuracy: 84.61%\n",
      "\n",
      "Epoch [7/10] | Batch [4727/4727] | Loss: 0.3985 | Acc: 85.98% | LR: 0.000206\n",
      "--- EPOCH 7 SUMMARY ---\n",
      "Average Loss: 0.3985\n",
      "Accuracy: 85.98%\n",
      "\n",
      "Epoch [8/10] | Batch [4727/4727] | Loss: 0.3525 | Acc: 87.07% | LR: 0.000095\n",
      "--- EPOCH 8 SUMMARY ---\n",
      "Average Loss: 0.3525\n",
      "Accuracy: 87.07%\n",
      "\n",
      "Epoch [9/10] | Batch [4727/4727] | Loss: 0.3186 | Acc: 87.98% | LR: 0.000024\n",
      "--- EPOCH 9 SUMMARY ---\n",
      "Average Loss: 0.3186\n",
      "Accuracy: 87.98%\n",
      "\n",
      "Epoch [10/10] | Batch [4727/4727] | Loss: 0.3028 | Acc: 88.36% | LR: 0.000000\n",
      "--- EPOCH 10 SUMMARY ---\n",
      "Average Loss: 0.3028\n",
      "Accuracy: 88.36%\n",
      "\n",
      "--- Training Finished ---\n",
      "\n",
      "--- Weights successfully saved to /kaggle/working/simplenet_weights.pth ---\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def conv_block(chan_in, chan_out, kern=3):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(chan_in, chan_out, kern, padding=kern//2), # <-- Stride is 1 by default\n",
    "        nn.BatchNorm2d(chan_out), # <-- Added for stability and speed\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            conv_block(1, 128), # 32x32\n",
    "            nn.MaxPool2d(2, 2), # 16x16\n",
    "            conv_block(128, 256), # 16x16\n",
    "            nn.MaxPool2d(2, 2), # 8x8\n",
    "            conv_block(256, 64), # 8x8\n",
    "            nn.MaxPool2d(2, 2), # 4x4\n",
    "            conv_block(64, 96), # 4x4\n",
    "            conv_block(96, 96), # 4x4\n",
    "            nn.Conv2d(96, 32, 1), # 1x1 convolution to reduce channels\n",
    "            nn.Flatten(), # 32 * 4 * 4 = 512\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1), # <-- Crucial regularization\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1), # <-- Crucial regularization\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1), # <-- Crucial regularization\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1), # <-- Crucial regularization\n",
    "            nn.Linear(512,span)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "bs = SimpleNet()\n",
    "bs.to(device)\n",
    "# ðŸ› FIXED: Using a lower, more stable learning rate (0.001)\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = optim.Adam(bs.parameters(), lr=LEARNING_RATE)\n",
    "SPAN = span\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "# Use a scheduler to gradually decrease LR over the whole training run\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=len(dataloader) * NUM_EPOCHS\n",
    ")\n",
    "\n",
    "# --- 5. ADVANCED TRAINING LOOP ---\n",
    "\n",
    "print(f\"--- Starting Training ---\")\n",
    "print(f\"Model: SimpleNet (Classes: {SPAN}, Initial LR: {LEARNING_RATE})\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    bs.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # Iterate over the data loader\n",
    "    for batch_idx, (image, label) in enumerate(dataloader):\n",
    "        \n",
    "        # 1. Prepare Data\n",
    "        optimizer.zero_grad()\n",
    "        output = bs(image.to(device))\n",
    "        \n",
    "        # Convert label (string list) to integer array, then to a Long Tensor\n",
    "        # ðŸ› FIXED: Ensures targets are torch.long for CrossEntropyLoss\n",
    "        targets = torch.from_numpy(get_target_ids(label)).long().to(device)\n",
    "        \n",
    "        # 2. Forward Pass & Loss\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        # 3. Backward Pass & Optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step() # Update learning rate\n",
    "\n",
    "        # 4. Statistics Tracking\n",
    "        running_loss += loss.item() * image.size(0)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += targets.size(0)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "        # Report every 100 batches (or less if the dataset is small)\n",
    "        REPORT_FREQ = 20\n",
    "        if (batch_idx + 1) % REPORT_FREQ == 0 or (batch_idx + 1) == len(dataloader):\n",
    "            current_loss = running_loss / total_samples\n",
    "            current_accuracy = 100 * correct_predictions / total_samples\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] | '\n",
    "                  f'Batch [{batch_idx+1}/{len(dataloader)}] | '\n",
    "                  f'Loss: {current_loss:.4f} | '\n",
    "                  f'Acc: {current_accuracy:.2f}% | '\n",
    "                  f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}',end='\\r')\n",
    "            \n",
    "    # Calculate and report end-of-epoch statistics\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    print(f'\\n--- EPOCH {epoch+1} SUMMARY ---')\n",
    "    print(f'Average Loss: {epoch_loss:.4f}')\n",
    "    print(f'Accuracy: {epoch_accuracy:.2f}%\\n')\n",
    "\n",
    "print(\"--- Training Finished ---\")\n",
    "WEIGHTS_PATH = '/kaggle/working/simplenet_weights.pth'\n",
    "save_checkpoint(bs, WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:28:33.282119Z",
     "iopub.status.busy": "2025-11-12T06:28:33.281611Z",
     "iopub.status.idle": "2025-11-12T06:28:33.285915Z",
     "shell.execute_reply": "2025-11-12T06:28:33.285173Z",
     "shell.execute_reply.started": "2025-11-12T06:28:33.282094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TestData = HASYDataset(test_csv)\n",
    "test_dataloader = DataLoader(TestData, batch_size=64, shuffle=False, num_workers=2) # Larger batch size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:28:38.830113Z",
     "iopub.status.busy": "2025-11-12T06:28:38.829415Z",
     "iopub.status.idle": "2025-11-12T06:29:17.250851Z",
     "shell.execute_reply": "2025-11-12T06:29:17.249873Z",
     "shell.execute_reply.started": "2025-11-12T06:28:38.830084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Testing ---\n",
      "\n",
      "======================================\n",
      "FINAL TEST RESULTS (16992 samples):\n",
      "Test Loss: 0.4753\n",
      "Test Accuracy: 84.56%\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 6. DEDICATED TESTING LOOP ---\n",
    "\n",
    "def test_loop(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset and prints final metrics.\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"--- Starting Testing ---\")\n",
    "\n",
    "    # Disable gradient calculations during evaluation\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloader:\n",
    "            \n",
    "            # 3. Move input data and targets to the device\n",
    "            image = image.to(device)\n",
    "\n",
    "            # Prepare targets\n",
    "            targets = torch.from_numpy(get_target_ids(label)).long().to(device) \n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(image)\n",
    "            \n",
    "            # Calculate loss and statistics\n",
    "            test_loss += criterion(output, targets).item() * image.size(0)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += targets.size(0)\n",
    "            # Use .cpu() for accurate total sum on CPU\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    # Calculate final metrics\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'\\n======================================')\n",
    "    print(f'FINAL TEST RESULTS ({total} samples):')\n",
    "    print(f'Test Loss: {avg_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'======================================\\n')\n",
    "\n",
    "\n",
    "# Run the test loop on the fully trained model\n",
    "test_loop(bs, test_dataloader, criterion)\n",
    "\n",
    "# Clean up mock data (optional)\n",
    "# import shutil\n",
    "# if os.path.exists(start):\n",
    "#     shutil.rmtree(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T06:30:04.918866Z",
     "iopub.status.busy": "2025-11-12T06:30:04.918239Z",
     "iopub.status.idle": "2025-11-12T06:30:05.134318Z",
     "shell.execute_reply": "2025-11-12T06:30:05.133657Z",
     "shell.execute_reply.started": "2025-11-12T06:30:04.918835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SINGLE IMAGE PREDICTION RESULTS ---\n",
      "Input Image: /kaggle/input/hasyv2-dataset-friend-of-mnist/HASYv2/classification-task/fold-1/../../hasy-data/v2-05632.png\n",
      "Predicted Class ID: 18 / \\$\n",
      "Confidence: 0.9997\n",
      "\n",
      "Top 5 Predictions:\n",
      "  1. Class ID 18 / \\$: Confidence 0.9997\n",
      "  2. Class ID 171 / \\%: Confidence 0.0002\n",
      "  3. Class ID 19 / \\{: Confidence 0.0001\n",
      "  4. Class ID 227 / \\between: Confidence 0.0000\n",
      "  5. Class ID 234 / \\nsubseteq: Confidence 0.0000\n",
      "Actual: \\$\n",
      "Image:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAsklEQVR4nO2VSw6AMAhEwXj/K+NC46JWmJmq0cSuTKS88hnwiDD4uLuZUVcm3FQ7c/57fbKRr0YBu/fmmzpKitwd5/lZ7N3kHP2WqSsi6N5/ootwRtFF44zbdcABBDWIbXoZgGp5DtC0v0zKIjhmXGCcKrljysvYqCJHROMRCWhUyWVtdKHlQ/ACAMgYHRX6uEYKiIgDXZkCfrPMY0wcgQIq9sG4mOkisxP7ZQvnB3wSsACYUEtQBaFttAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as displayImage\n",
    "def predict_single_image(model, image_path, device):\n",
    "    \"\"\"\n",
    "    Loads a single image, processes it, and returns the model's prediction, \n",
    "    confidence, and the top 5 predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load and Transform Image\n",
    "    try:\n",
    "        # Load as grayscale (L) and apply the same transformations as training\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        input_tensor = transform(image)\n",
    "        \n",
    "        # Add a batch dimension: [C, H, W] -> [1, C, H, W]\n",
    "        input_batch = input_tensor.unsqueeze(0) \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {os.path.join(start, image_path)}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or transforming image: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Move to Device and Set to Evaluation Mode\n",
    "    input_batch = input_batch.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 3. Generate Prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # 4. Process Output\n",
    "    # Convert logits to probabilities using Softmax\n",
    "    probabilities = nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    # Get the top prediction and its confidence\n",
    "    confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    # Get the top 5 predictions\n",
    "    top5_confidences, top5_indices = torch.topk(probabilities, 5)\n",
    "\n",
    "    # Convert tensors to standard Python values/lists\n",
    "    predicted_class_id = predicted_class.item()\n",
    "    confidence_value = confidence.item()\n",
    "\n",
    "    print(f'\\n--- SINGLE IMAGE PREDICTION RESULTS ---')\n",
    "    print(f'Input Image: {image_path}')\n",
    "    print(f'Predicted Class ID: {predicted_class_id} / {classes[predicted_class_id]}')\n",
    "    print(f'Confidence: {confidence_value:.4f}')\n",
    "    print(f'\\nTop 5 Predictions:')\n",
    "    for i in range(5):\n",
    "        class_id = top5_indices[0][i].item()\n",
    "        conf = top5_confidences[0][i].item()\n",
    "        print(f'  {i+1}. Class ID {class_id} / {classes[class_id]}: Confidence {conf:.4f}')\n",
    "\n",
    "# Run single image prediction\n",
    "idx = test_csv.iloc[5600]\n",
    "path = start+\"/\"+idx[\"path\"]\n",
    "\n",
    "# predict_single_image(bs,path,device)\n",
    "predict_single_image(bs, path, device)\n",
    "print(\"Actual:\",idx[\"latex\"])\n",
    "print(\"Image:\")\n",
    "displayImage(path)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1916,
     "sourceId": 3307,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
